# Canonicity in the Score Entropy Discrete Diffusion Model

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## Acknowledgements

Much of this repo is cloned from https://github.com/louaaron/Score-Entropy-Discrete-Diffusion, which contains a PyTorch implementation for the paper [Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution
](https://arxiv.org/abs/2310.16834) by [Aaron Lou](https://aaronlou.com), [Chenlin Meng](https://cs.stanford.edu/~chenlin/) and [Stefano Ermon](https://cs.stanford.edu/~ermon/). See the SEDD_README folder for a description of the source repo.

The remainder of this repo is dedicated to investigating the properties and influence of non-canonical tokenizations in the SEDD model. This research is built upon Renato Geh's research on canonicity in autoregressive models, detailed in his [tokenization](https://github.com/RenatoGeh/tokenization) repository and the paper [Where is the signal in tokenization space?](https://arxiv.org/pdf/2408.08541), and has been advised and directed by Renato throughout the process. 

## Context

When generating text, language models will sometimes generate a non-canonical sequence -- that is, a sequence of tokens T that can be interpreted as a string S (e.g., "Alice forced Bob to move"), but is different from the token sequence T' that is generated by passing S through the canonical tokenizer (in our case, GPT2TokenizerFast). In the above example, the word "forced" may be canonically encoded as one token, but is broken into the two tokens "for" and "ced" in the model's output. When models tokenize non-canonically, the text tends to be of lower quality (i.e., higher perplexity). Causally, one can interpret this as being due to a "loss of meaning" -- that is, because the generation of tokens is not independent, all tokens within the same context window as the non-canonical tokens are sampled conditional on a somewhat nonsensical context. The research seeks to better understand the emergence and effects of non-canonical tokenizations, and to directly intervene in the denoising (inference) process to improve performance.

## Functionality

The first stages of the research involved a cursory assessment of canonicity and performance for varying sequence lengths. This preliminary research primarily utilized the (renamed) scripts old_main.py and old_generate_graphs.py. The script old_main.py contains four functions, each of which uses SEDD to generate samples and performs one or more additional functionalities: check_canonicity_many() computes the percent of samples that are fully canonical for each sequence length; check_edit_distance() computes the average Levenshtein edit distance between the canonical and non-canonical tokenizations; compare_likelihoods() computes the average log-likelihood of both the canonical and non-canonical tokenizations using GPT-2 as the predictive language model; and do_it_all() computes the percent canonicity, average log-likelihood, and average log-likelihoods for the same samples, in order to determine relationships between these metrics. 

The most recent stages of research have focused on investigating the emergence of non-canonical tokens over the course of reverse diffusion (denoising) steps. For all samples that are generated, we use a CSV to keep track of various data, including all the variables from the preliminary research as well as the list of canonical and non-canonical tokens for each sample. The script generate_samples_indiv.py holds the sequence length constant at 1024 and generates sequences using a varying number of denoising steps. The script generate_samples_batch.py goes one step further: it holds the step count constant at 1024, but for each sample it stores the data after every denoising step. This allows us to determine exactly at which steps non-canonical tokens are introduced as tokens are unmasked, as well as monitor the sample quality over the course of denoising.

## Findings

All visualizations referenced below can be found in the Graphs/ folder.

Key findings from the preliminary research:
1. canonicity_plot.png: As expected, longer model outputs are less likely to be canonical. The plot also illustrates the fact that tokens are not generated independently (where we would expect to see exponential decay of canonicity).
2. log_likelihood_plot.png and log_likelihood_difference.png: The non-canonical log-likelihood was consistently higher than the canonical log-likelihood. While initially an unexpected result, this naturally stems from the fact that non-canonical tokens tend to only be generated when they are sampled with higher probability than canonical tokens, thus by definition resulting in a higher log-likelihood than the canonically retokenized sequence. One suprising element of this finding is the fact that this holds true despite the fact that log-likelihood was evaluated using GPT-2, indicating a remarkable similarity in the behavior of SEDD and GPT-2.
3. log_likelihoods_classified.png: In contrast to the above result, samples that were *naturally* canonical (i.e., not retokenized) had slightly higher log-likelihood than those that were non-canonical. While the previous finding was somewhat surprising, this finding was simply a confirmation of the intuition that non-canonicity impairs model performance.
4. Other graphs: edit_distance_plot.png, combined_analysis_plot_2.png (yielded expected results).

Key findings from recent research: 
1. canonicity_bar_graph.png, edit_distance_scatterplot.png, original_log_likelihoods_scatterplot.png, original_log_log_likelihoods_scatterplot.png log_likelihood_gains_scatterplot.png, split_canonicity.png: each of these graphs correspond to data that was generated by generate_samples_indiv.py, and all yielded expected results. That is, as step count increases, we see an improvement in model performance (greater canonicity and log-likelihood), as well as a smaller divergence between canonical and non-canonical samples with respect to all metrics (edit distance, log likelihood).
2.  transition_and_canonicity_frequency.png: this is the first graph corresponding to generate_samples_batch.py, where metrics were tracked *over the course of denoising* for 100 samples. The graph shows that, as [MASK] tokens are removed, samples quite rapidly become non-canonical. "Transition frequency" indicates at which step the sample became non-canonical, and is highly concentrated at low step counts.
3.  mask_transition_frequency.png: the graph shows that, while there is some amount of randomness in the unmasking process, on average exactly one token is unmasked at each denoising step. As such, it is always near the end of denoising that the last [MASK] token is removed.
4.  Other graphs: avg_edit_distance_linegraph.png, perplexity_vs_steps.png, perplexity_difference_vs_steps.png (yielded expected results).
